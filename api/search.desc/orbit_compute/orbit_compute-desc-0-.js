searchState.loadedDescShard("orbit_compute", 0, "Orbit Compute - Heterogeneous Acceleration Engine\nHardware capability detection and runtime feature discovery\nCPU SIMD acceleration implementations CPU compute …\nConvenience function to create a new heterogeneous …\nMain heterogeneous acceleration engine Heterogeneous …\nError types for heterogeneous computing operations Error …\nInitialize the heterogeneous compute engine with runtime …\nLinux platform-specific optimizations\nMemory management optimizations for accelerated computing …\nSystem monitoring and resource tracking System monitoring …\nQuery analysis and workload characterization Query …\nWorkload scheduling and optimal hardware selection …\nx86_64 architecture-specific optimizations\nA10 - Professional graphics\nA100 PCIe 40GB - Server variant\nA100 PCIe 80GB - Server variant\nA100 SXM 40GB - Standard ML training\nA100 SXM 80GB - ML training powerhouse\nA10G - Graphics and AI inference\nA15 Bionic chip\nA16 Bionic chip\nA16 Bionic Neural Engine (17 TOPS)\nA-series (iOS devices)\nA17 Pro Neural Engine (35 TOPS)\nAArch64 architecture (ARM64)\nAMD processors\nAMD GPU\nAMD GPU architectures with enhanced data center support\nAMD GPU memory types\nAMD Neural accelerator\nAMD-specific optimization features with enhanced EPYC …\nAMD-specific CPU features for EPYC and Ryzen processors\nARM Mali GPU\nARM vendor-specific optimizations\nARM SIMD instruction sets\nARM-specific specialized compute capabilities\nARM vendors and their SoCs\nAVX capabilities with detailed support levels\nAVX support levels\nAmazon Web Services\nTypes of custom accelerators\nActive air cooling\nAda Lovelace (RTX 40 series, L4, L40S)\nAdreno 730 (Snapdragon 8 Gen 1)\nAdreno 740 (Snapdragon 8 Gen 2)\nAdreno 750 (Snapdragon 8 Gen 3)\nQualcomm Adreno GPU details\nAdreno GPU model variants\nAdreno X1-75 (Snapdragon X Plus)\nAdreno X1-85 (Snapdragon X Elite)\nIntel Alder Lake (12th gen)\nAmazon Graviton\nAMD GPU details\nAmpere (RTX 30 series, A100, A10G)\nAndroid platform optimizations\nApple Silicon\nApple Silicon GPU\nApple Silicon chip variants\nApple Silicon GPU details\nApple Neural Engine\nApple Neural Engine versions\nApple Silicon optimizations\nIntel Arc (discrete)\nAudio processing\nMicrosoft Azure\nB100 PCIe 128GB - PCIe variant of B100\nB100 SXM 192GB - Next-gen AI training flagship\nB200 SXM 288GB - Ultra-large memory AI training\nB40 PCIe 48GB - Mid-range Blackwell for inference\nBMI (Bit Manipulation Instructions) support\nEPYC 9004 “Bergamo” series (Zen 4c - cloud optimized)\nBlackwell (B100, B200, GB200 series) - Next-gen AI/ML …\nCDNA 1 (MI100 series)\nCDNA 1 data center GPU models (MI100 series)\nCDNA 2 (MI200 series)\nCDNA 2 data center GPU models (MI200 series)\nCDNA 3 (MI300 series - latest data center)\nCDNA 3 data center GPU models (MI300 series)\nCPU architecture enumeration with detailed capabilities\nComprehensive CPU capability detection\nCache hierarchy information\nCloud-specific optimizations for Bergamo and similar\nCloud provider types for GPU deployments\nSupported compute APIs for GPU\nComputer vision\nGPU cooling requirements\nCore configuration details (used by Apple chips)\nCore configuration and topology\nCryptographic acceleration\nCryptographic operations\nCustom/proprietary accelerator\nCustom accelerator information\nDDR4 system memory\nDDR5 system memory\nDeep learning inference\nDeep learning training\nDSP capabilities\nData center cooling\nDigital Ocean\nDimensity 8300\nDimensity 9300\nMediaTek Dimensity chip variants\nEPYC processor-specific capabilities\nAMD EPYC processor models with detailed specifications\nEPYC model type enum for pattern matching\nEPYC processor-specific optimizations\nEnterprise security features\nExynos 2200 (Galaxy S22)\nExynos 2400 (Galaxy S24)\nSamsung Exynos chip variants\nFuture RDNA 4 models\nGB200 SuperChip - Grace + Blackwell superchip\nGCN architecture\nGoogle Cloud Platform\nGaussian &amp; Neural Accelerator\nComprehensive GPU capabilities across vendors\nIndividual GPU device information\nGPU performance characteristics\nGPU performance metrics for different precision types\nGPU performance profiles for different workload types\nGPU power consumption profile\nGPU thermal characteristics\nGPU vendor enumeration with detailed specifications\nGeneral compute\nEPYC 9004 “Genoa” series (Zen 4)\nEPYC 7004 “Genoa-X” with 3D V-Cache\nGraph analytics\nGraviton 2\nGraviton 3\nGraviton 4\nAmazon Graviton chip variants\nH100 NVL 94GB - Large memory variant\nH100 PCIe 80GB - Server deployment\nH100 SXM 80GB - Data center flagship\nH200 SXM 141GB - Latest with HBM3e\nIntel Haswell family\nHexagon 760 (Snapdragon 8 Gen 1)\nHexagon 770 (Snapdragon 8 Gen 2)\nHexagon 780 (Snapdragon 8 Gen 3)\nQualcomm Hexagon DSP details\nHexagon DSP version enumeration\nHopper (H100, H200 series) - Latest for AI/ML\niOS platform optimizations\nISP capabilities\nIntel Ice Lake\nInfinity Fabric optimization settings\nIntegrated GPU information\nIntel processors\nIntel GPU\nIntel GPU details\nIntel GPU architectures\nIntel Neural Compute\nIntel Neural Compute versions\nIntel-specific optimization features\nIntel-specific CPU features\nIntel Xe architecture details\nIntel Iris\nL4 - Inference optimized\nL40S - Professional workstation\nLPDDR4X (mobile)\nLPDDR5 (mobile)\nLPDDR5X (latest mobile)\nLinux platform optimizations\nLiquid cooling required\nM1 series\nStandard M1\nM1 series Neural Engine (15.8 TOPS)\nM1 Max\nM1 Max Neural Engine (15.8 TOPS)\nM1 Pro\nM1 Pro Neural Engine (15.8 TOPS)\nM1 Ultra\nM1 chip variants\nM2 series\nStandard M2\nM2 series Neural Engine (15.8 TOPS)\nM2 Max\nM2 Max Neural Engine (15.8 TOPS)\nM2 Pro\nM2 Pro Neural Engine (15.8 TOPS)\nM2 Ultra\nM2 chip variants\nM3 series\nStandard M3\nM3 series Neural Engine (18 TOPS)\nM3 Max\nM3 Max Neural Engine (18 TOPS)\nM3 Pro\nM3 Pro Neural Engine (18 TOPS)\nM3 chip variants\nM4 series (future)\nM4 base variant\nM4 Max variant\nM4 Pro variant\nM4 chip variants (future)\nMI100 - First generation CDNA\nMI210 - Entry-level CDNA2\nMI250 - Standard CDNA2 model\nMI250X - 128GB HBM2e, flagship CDNA2\nMI300A - APU with CPU + GPU, 128GB unified memory\nMI300C - Compute-optimized variant\nMI300X - 192GB HBM3, optimized for AI inference\nmacOS platform optimizations\nARM Mali GPU details\nMatrix multiplications\nMatrix/Tensor operations\nMediaTek Dimensity\nMemory architecture characteristics\nMemory support characteristics for EPYC processors\nMemory types\nEPYC 7003 “Milan” series (Zen 3)\nEPYC 7003 “Milan-X” with 3D V-Cache\nNatural language processing\nNeural Processing Unit in Intel processors\nNPU capabilities\nNUMA (Non-Uniform Memory Access) optimizations\nNUMA topology information\nNVIDIA Tegra\nNVIDIA GPU\nEPYC 7001 “Naples” series (Zen)\nNetwork packet processing\nNeural engine and AI accelerator capabilities\nNo dedicated neural acceleration\nNVIDIA GPU architectures with enhanced support\nNVIDIA GPU details with enhanced cloud and model support\nSpecific NVIDIA GPU models for cloud deployments\nOn-premises or bare metal\nOryon custom core configuration (Snapdragon X series)\nOryon performance profile\nOther x86-64 compatible processors\nOther ARM processors\nOther Exynos variant\nOther Dimensity variant\nOther Tegra variant\nOther Snapdragon variants\nOther GPU vendor\nOther architecture\nOther Adreno model\nOther Intel GPU\nOther cloud provider\nOther Hexagon version\nOther Intel neural compute\nOther memory type\nOther EPYC model\nPascal (GTX 10 series)\nPassive cooling (fanless)\nPlatform-specific optimizations\nQualcomm Snapdragon\nQualcomm Adreno GPU\nQualcomm AI Engine (Hexagon DSP + AI accelerator)\nQualcomm Snapdragon optimizations\nRDNA 1 (RX 5000 series)\nRDNA 1 GPU models\nRDNA 2 (RX 6000 series)\nRDNA 2 GPU models\nRDNA 3 (RX 7000 series)\nRDNA 3 GPU models\nRDNA 4 (RX 8000 series - 2024+)\nRDNA 4 GPU models (2024+)\nRTX 4080 - Mid-high consumer\nRTX 4090 - High-end consumer\nRX 8500 XT - Entry-level RDNA 4\nRX 8600 XT - Mid-range RDNA 4\nRX 8700 XT - Mid-high RDNA 4\nRX 8800 XT - High-end RDNA 4\nIntel Raptor Lake (13th gen)\nEPYC 7002 “Rome” series (Zen 2)\nSIMD instruction set capabilities\nSME support details\nSSE support levels\nSVE support details\nSamsung Exynos\nQualcomm Sensing Hub details\nSensor types supported by Sensing Hub\nIntel Skylake family\nSnapdragon 8 Gen 2\nSnapdragon 8 Gen 3 (flagship mobile)\nSnapdragon CPU configuration with heterogeneous cores\nQualcomm Snapdragon chip variants\nSnapdragon X Elite/Plus (ARM Windows laptops)\nSnapdragon X series CPU configuration (for ARM Windows)\nQualcomm Spectra ISP (Image Signal Processor)\nT4 - Cost-effective inference\nT4G - T4 with enhanced memory\nNVIDIA Tegra chip variants\nTegra Orin\nTegra Xavier\nIntel Tiger Lake (11th gen mobile)\nTime series analysis\nEPYC 9005 “Turin” series (Zen 5)\nTuring (RTX 20 series, T4)\nIntel UHD\nUnified memory (Apple Silicon)\nUniversal compute capability detection across all …\nUnknown microarchitecture\nV100 PCIe 32GB - Legacy server\nV100 SXM 16GB - Smaller memory\nV100 SXM 32GB - Legacy training\nVector similarity search\nCPU vendor-specific optimizations\nVideo encoding/decoding\nVirtualization-specific optimizations\nVolta (Titan V, V100)\nWindows platform optimizations\nWorkload-specific optimizations available on GPU\nTypes of workloads that can be optimized\nx86-64 specific CPU features and capabilities\nx86-64 microarchitecture families\nx86-64 SIMD instruction sets\nx86-64 CPU vendors\nx86-64 architecture (Intel/AMD)\nIntel Xe (integrated)\nAMD Zen (Ryzen 1000, EPYC 7001 “Naples”)\nAMD Zen 2 (Ryzen 3000, EPYC 7002 “Rome”)\nAMD Zen 3 (Ryzen 5000, EPYC 7003 “Milan”)\nAMD Zen 4 (Ryzen 7000, EPYC 9004 “Genoa”)\nAMD Zen 4c (EPYC 9004 “Bergamo” - cloud optimized)\nAMD Zen 5 (Future EPYC and Ryzen - 2024+)\nAMD Zen+ (Ryzen 2000)\nAccelerate framework\nAccelerator type/purpose\nAdreno GPU integration\nAdvanced SIMD support\nAdvanced SIMD support\nAdvanced Encryption Standard (AES) instructions\nAI Engine acceleration\nAI-enhanced image processing\nAI-enhanced processing\nAI operations per second\nAI performance in TOPS\nAlways-on processing capability\nAMD-specific optimizations\nAMD-specific features\nAndroid-specific optimizations\nApple-specific optimizations\nCPU architecture (x86-64 or AArch64)\nGPU architecture (Ampere, Ada Lovelace, Hopper, etc.)\nGPU architecture\nIntel GPU architecture\nARM vendor-specific optimizations\nARM SIMD features\nARM-specific specialized compute units\nAudio processing optimization\nAutomatic fabric frequency scaling\nAutomatic NUMA balancing\nWhether integrated GPU is available\nList of available GPU devices\nAVX instruction sets\nAVX-256 support\nAVX-512 support\nAVX-512 BFloat16 support\nAVX-512 Vector Byte Manipulation Instructions (VBMI)\nAVX-512 Vector Neural Network Instructions (VNNI)\nAdvanced Vector Extensions (AVX) support\nBase clock frequency in MHz\nBase frequency in GHz\nBase frequency in MHz\nBFloat16 support\nBF16 performance (brain float)\nBMI (Bit Manipulation Instructions) support\nBoost clock frequency in MHz\nBoost frequency in GHz\nCache coherency optimizations\nCache hierarchy information\nCache line size in bytes\nNumber of CPU Complex Dies (CCDs)\nControl-flow Enforcement Technology (CET)\nMemory channels per socket\nInstance type for cloud deployments\nCloud-specific optimizations (Bergamo)\nCloud provider information\nComputational photography features\nSupported compute APIs\nCompute capability version\nCompute units (CUDA cores, Stream processors, etc.)\nCompute units\nCompute units\nContainer workload optimization\nCooling requirements\nNumber of Oryon cores\nCore ML framework\nCore configuration and topology\nCores per CCD\nCPU cores per NUMA node\nCPU capabilities and SIMD instruction support\nCPU isolation support\nCreate EPYC result based on model type\nCross-socket bandwidth optimization\nCUDA support (NVIDIA only)\nCUDA compute capability\nCustom acceleration units\nCustom instruction set extensions\nDDR4 support\nDDR5 support\nDensity-optimized core configuration\nDetect all available compute capabilities on the current …\nDetect AMD microarchitecture and EPYC model\nFallback detection for non-macOS platforms\nDetect CPU capabilities including SIMD instruction sets\nDetailed microarchitecture and feature detection\nDetect Zen 1/2 architecture (Family 17h)\nDetect consumer Zen 1/2 models\nDetect EPYC models for Zen 1/2\nDetect Zen 3/4 architecture (Family 19h)\nDetect consumer Zen 3/4 models\nDetect EPYC models for Zen 3/4\nDirectCompute/DirectML (Windows)\nDirectML support\nDirectX support (Windows on ARM)\nIntel Deep Learning Boost\nIntel Deep Learning Boost (DL Boost)\nDSP (Digital Signal Processor) availability\nDSP type/vendor\nSupport for 2-socket configurations\nSupports dynamic voltage/frequency scaling\nError Correcting Code (ECC) support\nEfficiency cores (power saving)\nEfficiency cores (E-cores)\nEfficiency cores\nNVENC/NVDEC support\nEnterprise security features\nEPYC-specific features\nEPYC-specific optimization features\nExecution units\nFMA (Fused Multiply-Add) support\nHalf-precision floating point support\nFP16 performance\nFP16 compute performance in TFLOPS\nFP16 performance in TFLOPS\nFP32 performance\nFP32 compute performance in TFLOPS\nFP32 performance in TFLOPS\nFP8 performance (H100 and newer)\nGPU frequency in MHz\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGrand Central Dispatch optimization\nRDNA/GCN generation\nGPU capabilities across all available devices\nGPU core count\nGPU cores\nAndroid GPU Inspector compatibility\nHardware-assisted virtualization performance\nHardware-based attestation\nHexagon DSP integration\nHVX (Hexagon Vector Extensions) support\nWhether hyperthreading/SMT is enabled\nIdle temperature in Celsius\nAMD Infinity Fabric frequency (MHz)\nAMD Infinity Fabric optimizations\nINT4 performance\nINT8 performance\nINT8 performance in TOPS\nINT8 performance in TOPS\nIntegrated GPU availability\nIntel-specific optimizations\nIntel-specific features\nInter-die communication optimization\nInter-socket communication optimization\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\niOS-specific optimizations\nISP (Image Signal Processor) support\nISP vendor/type\nL1 data cache per core in KB\nL1 instruction cache per core in KB\nL2 cache per core in KB\nL3 cache total in KB\nL3 cache per CCD in MB\nLinux-specific optimizations\nLogical CPU cores (including hyperthreading)\nmacOS-specific optimizations\nMatrix operations performance (TFLOPS)\nSME matrix tile support\nMaximum memory capacity per socket (GB)\nMaximum frequency in GHz\nMaximum boost frequency in MHz\nMaximum memory speed (DDR4/DDR5) in MHz\nMaximum resolution supported\nMaximum supported resolution\nMaximum operating temperature in Celsius\nMaximum vector width supported\nMaximum power consumption in watts\nMemory architecture and unified memory support\nMemory bandwidth in GB/s\nMemory bandwidth in GB/s\nMemory bandwidth in GB/s\nMemory bandwidth optimization\nMemory channels supported\nMemory compression support\nMemory controllers\nNumber of memory controllers\nMemory bandwidth utilization efficiency (0.0-1.0)\nMemory bandwidth utilization efficiency\nMemory-to-fabric frequency ratio optimization\nMemory size in GB\nMemory Guard (hardware memory encryption)\nMemory interleaving capabilities\nMemory locality optimization\nMemory per NUMA node in GB\nMemory type\nMemory type\nMetal support (Apple only)\nMetal feature set\nMetal compute optimization\nMetal Performance Shaders\nMetal Performance Shaders\nMicroservice architecture optimization\nMulti-Instance GPU (MIG) support\nMinimum power consumption in watts\nML inference performance (TOPS)\nML training performance (TFLOPS)\nSpecific GPU model for cloud deployments\nAdreno GPU model\nMali GPU model\nIntel Memory Protection Keys (MPK)\nMemory Protection Extensions (MPX)\nMulti-tenant performance isolation\nMulti-threaded performance score (relative)\nDevice name/model\nAccelerator name\nARM NEON support\nARM NEON SIMD support\nNeural engine and AI accelerator capabilities\nNeural Engine cores\nApple Neural Engine integration\nNeural Engine optimization\nNeural Engine TOPS\nNNAPI (Neural Networks API) support\nNPU (Neural Processing Unit) support\nNPU vendor/type\nNUMA awareness\nNumber of NUMA nodes\nCache coherency and NUMA optimizations\nNUMA (Non-Uniform Memory Access) topology\nOpenCL support\nOpenCL version\nOpenMP support\nIntel Optane DC Persistent Memory support\nOptimal vector width in bytes\nOryon performance cores\nPCIe lanes supported\nCarry-less Multiplication (PCLMULQDQ)\nPerformance characteristics\nPerformance cores (mid-tier)\nPerformance cores (P-cores)\nPerformance cores\nPerformance multiplier for this workload\nPerformance characteristics\nPerformance characteristics\nPerformance characteristics\nPhysical CPU cores\nPlatform-specific optimizations available\nPlatform Quality of Service (QoS) features\nPlatform Quality of Service (QoS)\nPower-aware scheduling\nPower consumption in mW\nPower efficiency rating\nPower efficiency (TFLOPS per watt)\nPower efficiency (TOPS per Watt)\nPower efficiency modes\nPower consumption characteristics\nAMD Precision Boost\nAMD Precision Boost technology\nAMD Precision Boost Overdrive\nAMD Precision Boost Overdrive\nPrimary GPU for compute operations\nPrime cores (highest performance)\nSupport for 4-socket configurations (Milan and later)\nQualcomm-specific optimizations\nQuantization support\nRandom Number Generator (RDRAND)\nReal-time processing capability\nReal-time kernel support\nROCm/HIP support (AMD only)\nROCm support version\nRT cores (for ray tracing)\nSecure Boot support\nSecure Encrypted Virtualization (SEV)\nSecure Encrypted Virtualization (SEV)\nSecure Memory Encryption (SME)\nSecure Memory Encryption (SME)\nSEV-SNP (Secure Nested Paging)\nSecure Hash Algorithm (SHA) instructions\nShader cores\nShared system memory in GB\nSignal processing TOPS\nSilicon Root of Trust\nSIMD instruction set support\nSingle-threaded performance score (relative)\nAMD Smart Access Memory\nAMD Smart Access Memory (SAM)\nSME (Scalable Matrix Extension) support\nSME2 support\nSME (Scalable Matrix Extension) support\nAMD Simultaneous Multithreading (SMT)\nSpecial features enabled\nIntel Speed Select Technology (SST)\nSSE instruction sets\nStream processors\nSupported AI frameworks\nSupported operations\nSupported sensors\nSupported memory speeds (MHz)\nSVE (Scalable Vector Extension) support\nSVE2 support\nScalable Vector Extension support\nThermal design power in watts\nPower consumption in watts\nTensor accelerator availability\nTensor cores (for AI workloads)\nThermal characteristics\nIntel Thermal Velocity Boost\nIntel Thermal Velocity Boost\nThread affinity optimization\nIntel Thread Director (for hybrid architectures)\nIntel Thread Director (12th gen+)\nThread pool optimization\nAMD 3D V-Cache\nAMD 3D V-Cache technology\nThermal throttling temperature in Celsius\nTotal system memory in GB\nIntel Turbo Boost support\nIntel Turbo Boost Technology\nTypical power consumption in watts\nUnified memory architecture\nUnified memory support (Apple Silicon)\nUnified memory bandwidth\nUnified memory support (Apple Silicon)\n3D V-Cache size in MB\nSVE vector length in bits (128-2048)\nVector operations performance (TFLOPS)\nVector processing capability\nVector processing units\nGPU vendor and model\nGPU vendor\nCPU vendor-specific optimizations\nHexagon DSP version (e.g., Hexagon 780)\nISP version\nVirtualization optimizations (SEV, SME)\nVulkan compute support\nVulkan compute support\nVulkan API version\nWindows-specific optimizations\nWindows on ARM optimizations\nWindows ML\nWindows on ARM optimizations\nWorkload-specific optimizations\nWorkload type\nx86-64 SIMD features\nIntel Xe architecture details\nXe-HP (high performance)\nXe-HPG (high performance gaming)\nXe-LP (low power)\nXMX units for AI workloads\nCPU core configuration\nCPU core configuration\nCPU core configuration\nCPU core configuration\nM1 chip variant (base, Pro, Max, Ultra)\nM2 chip variant (base, Pro, Max, Ultra)\nM3 chip variant (base, Pro, Max)\nM4 chip variant (base, Pro, Max)\nAvailable CPU features\nAvailable ARM features\nMicroarchitecture details\nSystem-on-Chip details\nCPU vendor (Intel, AMD)\nARM vendor (Apple, Qualcomm, etc.)\nAvailability zone (optional)\nProject ID\nAWS region\nAzure region\nGCP region\nDO region\nResource group\nVPC UUID (optional)\nGCP zone\nTotal AI performance in TOPS\nCore ML optimization support\nEstimated AI performance in TOPS\nInference execution units\nFastCV computer vision support\nHexagon DSP details\nOpenVINO support\nROCm AI framework support\nSensing Hub details\nPerformance in TOPS\nAI performance in TOPS\nUnified memory access\nNeural Engine version/generation\nNeural compute version\nXDNA AI accelerator version\nAdreno GPU\nAdreno GPU\nAdreno GPU\nOptional Adreno GPU\nCPU configuration\nCPU configuration\nCPU configuration\nCPU configuration\nHexagon DSP\nHexagon DSP\nHexagon DSP\nModel name\nOryon custom cores\nSensing Hub\nSpectra ISP\nSpectra ISP\nCPU compute engine for SIMD operations\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreate a new CPU engine\nEngine configuration for graceful degradation\nEngine status information\nMain heterogeneous acceleration engine\nContinue operation even with degraded monitoring\nNumber of available compute units\nSystem capabilities\nSystem capabilities\nTimeout for compute unit responsiveness checks\nEngine configuration\nWhether system monitoring is degraded\nEnable graceful fallback when preferred compute units fail\nExecute a workload with graceful degradation\nFallback to CPU when other compute units are unavailable\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet current engine status with degradation information\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMaximum fallback attempts before giving up\nCreate a new heterogeneous engine with detected …\nCreate a new heterogeneous engine with specific …\nAdaptive workload scheduler\nCurrent system conditions (None if monitoring degraded)\nSystem monitor\nFallback to CPU execution when other compute units fail\nTry to execute a workload with the optimal compute unit\nGPU compute API initialization failed\niOS API unavailable\nSystem information access denied\nMemory alignment requirements not met\nAndroid specific errors\nAndroid specific errors\nApp store restrictions\nBackground execution limited\nMemory bandwidth insufficient for operation\nFailed to detect CPU features\nCUDA driver error\nHardware capability detection errors\nHardware capability detection specific errors\nGPU command buffer execution failed\nMain error type for compute operations\nResult type alias for compute operations\nCompute unit not responsive\nConfiguration and validation errors\nConfiguration and validation errors\nConflicting scheduling constraints\nConflicting configuration options\nGPU context creation failed\nConvergence failure\nCore Foundation error\nCore ML framework error\nDatabase corruption detected\nMemory corruption detected\nCritical system errors requiring immediate attention\nCritical severity - immediate attention required, system …\nCritical error types requiring immediate attention\nData loss imminent\nData transfer error (CPU ↔ GPU, etc.)\nPerformance database and persistence errors\nPerformance database errors\nDeadline cannot be satisfied\nConfiguration dependency not met\nGPU device not found\nDevice tree access error\nDirectX error\nDivision by zero\nWindows driver error\nNeural Engine driver communication error\nHardware driver issues\nGPU driver error\nEnvironment variable error\nContains the error value\nTrait for error context enhancement\nError severity levels\nExecution engine errors\nExecution engine errors\nExecution timed out\nFeature flag configuration error\nMemory fragmentation prevents allocation\nGPU-specific errors (Metal, CUDA, ROCm, etc.)\nFailed to detect GPU capabilities\nGPU-specific errors\nHardware failure detected\nPlatform-specific hardware not available\nHigh severity - operation should be aborted but system can …\nGeneric I/O errors\nIOKit error\niOS specific errors\niOS specific errors\nPlatform API version incompatible\nIncompatible hardware architecture\nSystem power state incompatible with operation\nInference execution failed\nInput data validation failed\nGPU compute capability insufficient\nEntitlements insufficient\nGPU memory bandwidth insufficient\nInsufficient performance data for decision making\nInsufficient permissions for hardware access\nPlatform permissions insufficient\nInsufficient system resources\nDatabase integrity check failed\nInvalid memory access\nInvalid floating point result (NaN, Inf)\nInvalid kernel parameters\nInvalid parameter value\nInvalid database query\nInvalid scheduling request\nCompute kernel compilation failed\nGPU kernel launch failed\nLinux kernel module error\nLearning algorithm error\nLinux specific errors\nLinux specific errors\nFailed to load performance database\nSystem load monitoring failed\nDatabase lock contention\nLow severity - operation can continue with degraded …\nmacOS specific errors\nmacOS specific errors\nMemory mapping failed\nMatrix operation error\nMedium severity - operation should be retried or …\nMemory and resource allocation errors\nMemory allocation on compute unit failed\nGPU memory allocation failed\nMemory corruption detected\nMemory management errors\nMemory leak detected\nMetal framework error\nFailed to migrate database schema\nMissing required configuration\nMissing required system APIs\nModel compilation failed\nModel size exceeds Neural Engine capacity\nResource monitoring access denied\nAndroid NDK error\nNNAPI error\nNeural Engine and AI accelerator errors\nFailed to detect neural engine capabilities\nNeural Engine specific errors\nNeural Engine access restricted\nNo compute units available for the requested workload\nNo GPU available for acceleration\nNeural Engine not available on this platform\nPrecision or numerical accuracy error\nNumerical computation error types\nNumerical instability\nContains the success value\nOpenCL platform error\nOut of memory\nOverflow in computation\nConfiguration file parsing error\nPerformance regression detected\nAndroid permissions error\nPlatform-specific errors\nPlatform-specific errors\nPower management API error\nPower management error\nPrecision loss detected\nprocfs access error\nMemory protection error\nQuality of Service requirements cannot be met\nModel quantization failed\nROCm error\nRegistry access error\nResource allocation failed\nResource exhaustion errors\nResource exhaustion critical\nRuntime configuration change not allowed\nRuntime execution error\nPerformance sample validation failed\nSandbox restriction\nFailed to save performance database\nScheduler overloaded\nScheduling and workload management errors\nScheduling system errors\nSecurity framework restriction\nSystem security restrictions\nSecurity violation detected\nFailed to read system sensors\nSerialization/deserialization errors\nGPU shader compilation failed\nQualcomm Snapdragon specific error\nSynchronization error between compute units\nGPU synchronization timeout\nsysfs access error\nSystem monitoring and resource errors\nSystem API call failed\nPlatform system call failed\nSystem configuration error\nSystem monitoring and resource errors\nSystem integrity compromised\niOS system resource limit\nAndroid system service error\nThermal monitoring API error\nSystem in emergency thermal state\nThermal emergency shutdown imminent\nNeural Engine thermal limiting\nThermal monitoring error\nGPU thermal throttling detected\nTimeout and deadline errors\nUnderflow in computation\nUnified memory allocation failed (Apple Silicon)\nUnrecoverable error state\nUnsupported model architecture\nUnsupported operation or feature\nUnsupported platform\nUnsupported precision for Neural Engine\nConfiguration schema version unsupported\nWorkload type not supported\nResult validation failed\nConfiguration validation failed\nDatabase version mismatch\nVulkan API error\nWMI query error\nWin32 API error\nWindows specific errors\nWindows specific errors\nWindows ML error\nCreate a capability detection error\nCreate a critical error\nCreate an execution error\nCreate an execution error with compute unit context\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreate a GPU error\nCreate a GPU error with context\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate an I/O error with context\nCheck if error is critical and requires immediate attention\nCheck if error is recoverable\nCreate a memory error\nCreate a neural engine error\nCreate a scheduling error\nCreate a scheduling error with workload type context\nGet error severity level\nAdd context to an error\nAdd context using a closure (lazy evaluation)\nLinux platform manager\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreate a new Linux platform manager\nMemory allocator with platform-specific optimizations\nAligned memory allocation\nPlatform-specific memory optimizations\nMemory alignment requirements\nAllocate aligned memory with graceful fallback\nStandard aligned allocation\nGet the memory pointer\nDetect optimal memory alignment for the platform\nDetect if unified memory is available (Apple Silicon)\nEnable memory prefetching\nFallback allocation with minimal requirements\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if large pages are used\nWhether large pages were used\nCheck if unified memory is used\nWhether this is unified memory\nMemory layout\nCreate a new memory allocator with platform detection\nEnable NUMA awareness on supported platforms\nPlatform-specific optimizations\nMemory pointer\nGet the allocation size\nAllocation size\nTry large page allocation (Linux/Windows)\nTry optimal allocation with platform-specific features\nWhether unified memory is available (Apple Silicon)\nUse large pages when available\nUse memory mapping when available\nLinux system monitor\nLinux system information\nMock monitor for testing/unsupported platforms\nMock system information\nMock system information for testing\nMock system monitor for testing\nMock system monitor configuration\nPlatform-specific system information\nUniversal system monitor that abstracts platform-specific …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet current system conditions\nGet mock system conditions\nGet platform-specific system information\nGet mock system information\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nLinux system monitoring implementation\nCreate a new system monitor for the current platform\nCreate a new mock system monitor\nStart background monitoring\nStart mock monitoring\nAMD GPU device\nBIOS information\nMotherboard information\nCPU statistics from /proc/stat\nIntel GPU device\nKernel information\nLinux CPU information\nLinux CPU monitor\nLinux cache information\nLinux distribution information\nLinux GPU information\nLinux GPU monitor\nLinux hardware information\nLinux memory information\nLinux memory monitor\nLinux power management capabilities\nLinux power monitor\nLinux system information\nLinux system monitor implementation\nLinux thermal monitor\nNVIDIA GPU device\nPower supply information\nThermal zone information\nAC power connected\nAMD GPU devices\nSystem architecture\nAvailable memory in GB\nCPU frequency (base) in MHz\nBattery present\nBIOS information\nMotherboard information\nBuffer memory in GB\nCache sizes\nCached system conditions\nCached memory in GB\nCapacity percentage (for batteries)\nVersion codename (if available)\nNumber of CPUs\nCPU frequency scaling available\nAvailable CPU governors\nCPU information\nCPU monitoring interface\nCritical temperature\nCUDA support (for NVIDIA)\nCurrent GPU frequency in MHz\nCurrent CPU governor\nCurrent power state\nBIOS date\nDetermine power state based on system conditions\nGPU device index\nDistribution information\nDriver in use\nDriver version\nCPU features/flags\nFree memory in GB\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGather system information from various Linux sources\nGet CPU cache information\nGet available CPU governors\nGet CPU information from /proc/cpuinfo\nGet CPU temperature from thermal zones\nGet CPU utilization by reading /proc/stat\nGet current system conditions\nGet current CPU governor\nGet distribution information from /etc/os-release\nGet GPU information (basic stub - would need specific GPU …\nGet GPU temperature (placeholder)\nGet hardware information from DMI\nGet kernel information from uname\nGet load average from /proc/loadavg\nGet memory information from /proc/meminfo\nGet memory utilization from /proc/meminfo\nGet power management capabilities\nGet power supplies from /sys/class/power_supply\nGet Linux system information\nGet thermal zones from /sys/class/thermal\nCPU governors available\nGPU information\nGPU monitoring interface\nGPU power management available\nHardware information\nHealth status\nHibernation support\nHostname\nDistribution ID (ubuntu, centos, etc.)\nIdle time\nDevice index\nDevice index\nDevice index\nInitialize CPU monitoring\nInitialize GPU monitoring\nInitialize power monitoring\nInitialize thermal monitoring\nIntel GPU devices\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nI/O wait time\nIRQ time\nCheck if system is thermal throttling\nKernel information\nL1 data cache size in KB\nL1 instruction cache size in KB\nL2 cache size in KB\nL3 cache size in KB\nNumber of logical processors\nDMI system manufacturer\nBoard manufacturer\nMaximum GPU frequency in MHz\nCPU frequency (max) in MHz\nMemory information\nMemory size in MB\nMemory monitoring interface\nMemory type (if available)\nCPU model name\nCurrent monitoring state\nMain monitoring loop\nDistribution name (Ubuntu, CentOS, etc.)\nGPU name/model\nPower supply name\nDevice name\nDevice name\nDevice name\nCreate a new Linux system monitor\nNice time\nNVIDIA GPU devices\nOnline status\nOpenCL support\nParse GPU vendor from vendor ID\nPassive temperature\nPCI device ID\nNumber of physical cores\nPower management capabilities\nPower limit in watts\nPower monitoring interface\nAvailable power supplies\nAvailable power supplies\nPresent status\nPretty name for display\nPrevious CPU stats for utilization calculation\nProcess a single GPU entry from /sys/class/drm\nDMI system product name\nBoard product name\nRead CPU frequency from …\nRead DMI field from /sys/class/dmi/id/\nRead GPU vendor and device IDs\nKernel release\nSample current system conditions\nDMI system serial number\nNumber of physical sockets\nSoft IRQ time\nMemory speed in MHz (if available)\nStart background monitoring\nSteal time\nPower supply type (Mains, Battery, etc.)\nSystem suspend support\nSwap free in GB\nSwap total in GB\nSystem time\nSystem information cache\nTemperature in Celsius\nCurrent temperature in millidegrees Celsius\nThermal monitoring interface\nAvailable thermal zones\nTotal memory in GB\nUser time\nUUID\nCPU vendor (GenuineIntel, AuthenticAMD, etc.)\nGPU vendor (NVIDIA, AMD, Intel)\nBIOS vendor\nDistribution version\nKernel version string\nDMI system version\nBIOS version\nBoard version\nVulkan support\nZone type (cpu, gpu, acpi, etc.)\nAvailable thermal zones\nAcceleration strategy recommendation\nCPU SIMD acceleration\nGPU acceleration\nHybrid approach\nNeural engine acceleration\nNo acceleration needed\nQuery analysis result\nAnalyze a query for acceleration opportunities\nQuery complexity score\nEstimated data size\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nRecommended acceleration strategy\nAMD AI accelerator\nIntel/AMD AVX2\nIntel/AMD AVX-512\nAdaptive workload scheduler that learns from performance …\nAggressive thermal management allowed\nAlternative scheduling options\nApple Neural Engine\nBrain floating point 16-bit\nBalanced power and performance\nBaseline performance score\nBest effort - no guarantees\nBitwise and logical operations\nConvolutional Neural Networks\nCPU with SIMD optimization\nCPU SIMD instruction set types\nNVIDIA CUDA\nCompute performance baselines\nCompute intensive operations\nAvailable compute units for workload execution\nConvolution and signal processing\nCritical - aggressive throttling\nCritical - maximum error detection and recovery\nData parallelism across compute units\nData size classification for workload characterization\nReasoning behind scheduling decisions\nPerformance degrading over time\nDiffusion models\nMicrosoft DirectCompute\nElement-wise arithmetic operations\nEmergency - emergency shutdown may occur\nEnergy efficiency considerations\nExtra large datasets requiring main memory (&gt; 32MB)\n16-bit floating point\n32-bit floating point\nGraph Neural Networks\nGPU compute\nGPU compute workloads\nGPU compute API selection\nGPU workload classification\nCompute shaders and general purpose computing\nHierarchical decomposition\nHigh reliability with error checking\nMaximum performance mode\nHistorical performance data favored this choice\nHot - may reduce performance\nHybrid workloads using multiple compute units\nHybrid execution across multiple units\nHybrid coordination strategies\n4-bit quantization\n8-bit integer quantization\nImage and signal processing\nPerformance improving over time\nInference precision levels\nFallback due to insufficient data\nIntel NPU\nLarge Language Models\nLarge datasets fitting in L3 cache (512KB - 32MB)\nLearning statistics for the performance database\nLow power mode (mobile devices)\nMachine learning training and inference\nMatrix multiplication and linear algebra\nMedium datasets fitting in L2 cache (64KB - 512KB)\nMemory bandwidth intensive operations\nMemory access patterns\nApple Metal compute\nAllow mild thermal throttling\nMixed precision\nNeural inference model types\nARM NEON\nNeural Engine / AI accelerator\nNeural engine type classification\nNeural Engine / AI inference workloads\nAvoid thermal throttling at all costs\nNormal operating temperature\nNormal thermal management\nCross-platform OpenCL\nParallel algorithms and reductions\nPerformance database storing historical execution metrics\nDetailed performance metrics\nIndividual performance sample\nPerformance trend analysis\nPipeline different stages across compute units\nPower saving mode\nSystem power state\nProducer-consumer pattern\nQuality of Service requirements\nQoS requirements drove decision\nQualcomm AI Engine (Hexagon DSP)\nRecurrent Neural Networks\nAMD ROCm/HIP\nRandom memory access\nRead-only data access\nReduction operations (sum, max, min)\nReliability level requirements\nResource semaphores for throttling concurrent workloads\nSIMD batch processing (vectors, matrices)\nSIMD operation types\nARM SME (Scalable Matrix Extension)\nARM SVE (Scalable Vector Extension)\nWorkload scheduling request\nScheduling decision result\nScheduling policy configuration\nSequential memory access\nSmall datasets fitting in L1 cache (&lt; 64KB)\nPerformance stable\nStandard reliability\nStreaming datasets that don’t fit in memory\nStrided memory access\nSystem conditions during performance sampling\nCurrent system load favored this choice\nSystem load monitoring\nThermal conditions influenced decision\nThermal constraint specification\nThermal limited state\nSystem thermal state\nThermal status information\nTiled/blocked memory access\nTranscendental functions (sin, cos, exp, log)\nTransformer models\nInsufficient data for trend analysis\nUser preference override\nVision Transformers\nCross-platform Vulkan compute\nWarm but within limits\nPerformance profile for a specific workload type\nWorkload type classification for performance profiling\nWrite-heavy operations\nEnable adaptive learning\nAdd CPU candidates based on SIMD capabilities\nAdd GPU candidates\nAdd neural engine candidates\nAlternative options considered\nAverage execution time in milliseconds\nQueue waiting time in milliseconds\nEnergy efficiency baseline\nBenchmark CPU baseline performance\nBenchmark GPU baseline performance\nBenchmark neural engine baseline performance\nCalculate score for a candidate compute unit\nCalculate performance metrics from execution\nCalculate sample quality score\nAvailable compute capabilities\nCompute unit performance baselines\nPerformance metrics per compute unit\nCompute unit used for execution\nAlternative compute unit\nConcurrent workload count\nConfidence level in the optimal choice (0.0-1.0)\nConfidence in baseline measurement\nConfidence score\nCPU baseline performance scores\nCurrent CPU load percentage\nCPU resource semaphore\nCPU temperature in Celsius\nCPU temperature in Celsius\nCPU utilization percentage\nDatabase creation timestamp\nDeadline for completion (optional)\nConfidence in the scheduling decision (0.0-1.0)\nReasoning for the decision\nDetermine appropriate GPU API for vendor\nEnergy efficiency weight (0.0-1.0)\nEnergy budget constraint\nEnergy efficiency (operations per joule)\nEstimated workload duration\nEstimated execution time\nExcluded compute units\nExecute a workload and collect performance metrics\nStandard deviation of execution time\nExpected performance metrics\nExpected performance\nFilter candidates by user preferences and exclusions\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGenerate candidate compute units for a workload\nGet current system conditions\nGet performance history for a workload type\nGPU baseline performance scores\nCurrent GPU load percentage\nGPU resource semaphores (per device)\nGPU temperature in Celsius\nGPU temperature in Celsius\nGPU utilization percentage\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nLast learning update\nLast update timestamp\nLearning statistics and confidence metrics\nLearning algorithm version\nMaximum acceptable latency\nMaximum queue depth per compute unit\nMemory bandwidth utilization percentage\nCurrent memory usage percentage\nMemory utilization percentage\nMeasured performance metrics\nMinimum confidence threshold for using learned preferences\nMinimum throughput requirement\nNeural engine baseline scores\nNeural engine semaphore\nCreate a new adaptive workload scheduler\nBest performing compute unit for this workload\nPeak memory bandwidth\nPeak throughput measurement\nPerformance history and learning data\nPerformance optimization weight (0.0-1.0)\nSystem power state\nPower management state\nAverage prediction accuracy\nPreferred compute units (empty = scheduler decides)\nPriority level (0-10, higher is more urgent)\nQuality of service requirements\nSample quality score (0.0-1.0)\nRecent performance samples for trend analysis\nEstimated time until thermal recovery\nReason why not selected\nReliability requirement\nResource semaphores for throttling\nResource utilization percentage\nRun initial baseline benchmarks\nRun periodic performance sampling\nNumber of samples collected\nSample collection frequency\nBackground performance sampling task\nSchedule a workload for execution\nScheduling policy configuration\nScore candidate compute units\nSelect the best candidate from scored options\nSelected compute unit for execution\nStart background performance sampling task\nStore a performance sample in the database\nSynthetic benchmark score\nSystem conditions during sampling\nCurrent system load monitoring\nThermal constraint\nThermal impact score (0.0-1.0)\nCurrent system thermal state\nThermal status monitoring\nThermal throttling status\nThermal management weight (0.0-1.0)\nThermal throttling active\nThroughput in operations per second\nSample timestamp\nTotal number of samples collected\nPerformance trend analysis\nPerformance trend analysis window\nUpdate workload profile based on new performance sample\nWorkload performance profiles indexed by workload type\nWorkload identifier\nWorkload that was executed\nWorkload type to be scheduled\nNumber of workload types profiled\nx86_64 architecture manager\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreate a new x86_64 architecture manager")