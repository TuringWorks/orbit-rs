# Digital Ocean Deployment Pipeline
# Purpose: Deploy Orbit-RS to Digital Ocean using Droplets with GPU support
# Features: Infrastructure provisioning, container deployment, monitoring setup

name: Digital Ocean Deployment

on:
  workflow_dispatch:
    inputs:
      deployment_environment:
        description: 'Deployment environment'
        required: false
        default: 'staging'
        type: choice
        options:
        - development
        - staging
        - production
      enable_gpu_droplets:
        description: 'Deploy GPU-enabled droplets'
        required: false
        default: false
        type: boolean
      droplet_count:
        description: 'Number of droplets to deploy'
        required: false
        default: '3'
        type: string
      gpu_droplet_count:
        description: 'Number of GPU droplets to deploy'
        required: false
        default: '1'
        type: string

env:
  DO_REGION: nyc3
  DEPLOYMENT_NAME: orbit-rs
  CONTAINER_REGISTRY: ghcr.io/${{ github.repository_owner }}/orbit-rs

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ inputs.deployment_environment || 'staging' }}
  cancel-in-progress: false  # Don't cancel deployment in progress

jobs:
  # ============================================================================
  # SETUP AND VALIDATION
  # ============================================================================

  validate-deployment:
    name: Validate Deployment Configuration
    runs-on: ubuntu-latest
    outputs:
      deployment-environment: ${{ steps.environment.outputs.environment }}
      enable-gpu: ${{ steps.gpu.outputs.enable-gpu }}
      droplet-count: ${{ steps.counts.outputs.droplet-count }}
      gpu-droplet-count: ${{ steps.counts.outputs.gpu-droplet-count }}
      deploy-to-do: ${{ steps.should-deploy.outputs.should-deploy }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Determine deployment environment
      id: environment
      run: |
        if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          ENVIRONMENT="${{ inputs.deployment_environment }}"
        elif [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          ENVIRONMENT="production"
        elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
          ENVIRONMENT="staging"
        else
          ENVIRONMENT="development"
        fi
        echo "environment=${ENVIRONMENT}" >> $GITHUB_OUTPUT
        echo "üéØ Deployment environment: ${ENVIRONMENT}"

    - name: Determine GPU deployment
      id: gpu
      run: |
        if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          ENABLE_GPU="${{ inputs.enable_gpu_droplets }}"
        else
          # Auto-enable GPU for production and staging
          if [[ "${{ steps.environment.outputs.environment }}" =~ ^(production|staging)$ ]]; then
            ENABLE_GPU="true"
          else
            ENABLE_GPU="false"
          fi
        fi
        echo "enable-gpu=${ENABLE_GPU}" >> $GITHUB_OUTPUT
        echo "üñ•Ô∏è GPU droplets enabled: ${ENABLE_GPU}"

    - name: Determine droplet counts
      id: counts
      run: |
        if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          DROPLET_COUNT="${{ inputs.droplet_count }}"
          GPU_DROPLET_COUNT="${{ inputs.gpu_droplet_count }}"
        else
          case "${{ steps.environment.outputs.environment }}" in
            "production")
              DROPLET_COUNT="5"
              GPU_DROPLET_COUNT="2"
              ;;
            "staging")
              DROPLET_COUNT="3"
              GPU_DROPLET_COUNT="1"
              ;;
            "development")
              DROPLET_COUNT="2"
              GPU_DROPLET_COUNT="1"
              ;;
          esac
        fi
        echo "droplet-count=${DROPLET_COUNT}" >> $GITHUB_OUTPUT
        echo "gpu-droplet-count=${GPU_DROPLET_COUNT}" >> $GITHUB_OUTPUT
        echo "üìä Droplet configuration: ${DROPLET_COUNT} standard, ${GPU_DROPLET_COUNT} GPU"

    - name: Check if should deploy
      id: should-deploy
      run: |
        # Deploy on main/develop branches or manual trigger
        if [[ "${{ github.ref }}" == "refs/heads/main" || "${{ github.ref }}" == "refs/heads/develop" || "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          echo "should-deploy=true" >> $GITHUB_OUTPUT
        else
          echo "should-deploy=false" >> $GITHUB_OUTPUT
        fi

    - name: Validate Digital Ocean configuration
      run: |
        # Check required environment variables (secrets)
        if [[ -z "${{ secrets.DO_API_TOKEN }}" ]]; then
          echo "‚ùå DO_API_TOKEN secret not set"
          exit 1
        fi
        if [[ -z "${{ secrets.DO_SPACES_ACCESS_KEY }}" ]]; then
          echo "‚ùå DO_SPACES_ACCESS_KEY secret not set"
          exit 1
        fi
        if [[ -z "${{ secrets.DO_SPACES_SECRET_KEY }}" ]]; then
          echo "‚ùå DO_SPACES_SECRET_KEY secret not set"
          exit 1
        fi
        echo "‚úÖ Digital Ocean credentials validated"

    - name: Validate deployment configuration files
      run: |
        # Check if deployment config exists
        if [[ ! -f "deploy/config/deployment-config.yaml" ]]; then
          echo "‚ùå Deployment configuration not found"
          exit 1
        fi
        
        # Validate YAML syntax
        python3 -c "import yaml; yaml.safe_load(open('deploy/config/deployment-config.yaml'))" || {
          echo "‚ùå Invalid YAML in deployment configuration"
          exit 1
        }
        
        echo "‚úÖ Deployment configuration validated"

  # ============================================================================
  # INFRASTRUCTURE PROVISIONING
  # ============================================================================

  provision-infrastructure:
    name: Provision Digital Ocean Infrastructure
    runs-on: ubuntu-latest
    needs: validate-deployment
    if: needs.validate-deployment.outputs.deploy-to-do == 'true'
    environment: ${{ needs.validate-deployment.outputs.deployment-environment }}
    outputs:
      vpc-id: ${{ steps.vpc.outputs.vpc-id }}
      firewall-id: ${{ steps.firewall.outputs.firewall-id }}
      load-balancer-id: ${{ steps.load-balancer.outputs.load-balancer-id }}
      droplet-ids: ${{ steps.droplets.outputs.droplet-ids }}
      gpu-droplet-ids: ${{ steps.gpu-droplets.outputs.gpu-droplet-ids }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install doctl (Digital Ocean CLI)
      uses: digitalocean/action-doctl@v2
      with:
        token: ${{ secrets.DO_API_TOKEN }}

    - name: Create or update VPC
      id: vpc
      run: |
        VPC_NAME="${{ env.DEPLOYMENT_NAME }}-vpc-${{ needs.validate-deployment.outputs.deployment-environment }}"
        
        # Check if VPC exists
        VPC_ID=$(doctl compute vpc list --format ID,Name --no-header | grep "${VPC_NAME}" | cut -d' ' -f1)
        
        if [[ -z "$VPC_ID" ]]; then
          echo "üåê Creating new VPC: ${VPC_NAME}"
          VPC_ID=$(doctl compute vpc create \
            --name "${VPC_NAME}" \
            --region "${{ env.DO_REGION }}" \
            --ip-range "10.116.0.0/20" \
            --format ID --no-header)
        else
          echo "üåê Using existing VPC: ${VPC_NAME} (${VPC_ID})"
        fi
        
        echo "vpc-id=${VPC_ID}" >> $GITHUB_OUTPUT

    - name: Create or update firewall
      id: firewall
      run: |
        FIREWALL_NAME="${{ env.DEPLOYMENT_NAME }}-firewall-${{ needs.validate-deployment.outputs.deployment-environment }}"
        
        # Check if firewall exists
        FIREWALL_ID=$(doctl compute firewall list --format ID,Name --no-header | grep "${FIREWALL_NAME}" | cut -d' ' -f1)
        
        if [[ -z "$FIREWALL_ID" ]]; then
          echo "üî• Creating new firewall: ${FIREWALL_NAME}"
          FIREWALL_ID=$(doctl compute firewall create \
            --name "${FIREWALL_NAME}" \
            --inbound-rules "protocol:tcp,ports:22,address:0.0.0.0/0 protocol:tcp,ports:50051,address:10.116.0.0/20 protocol:tcp,ports:8080,address:10.116.0.0/20 protocol:tcp,ports:9090,address:10.116.0.0/20" \
            --outbound-rules "protocol:tcp,ports:443,address:0.0.0.0/0 protocol:tcp,ports:80,address:0.0.0.0/0 protocol:tcp,ports:53,address:0.0.0.0/0 protocol:udp,ports:53,address:0.0.0.0/0" \
            --format ID --no-header)
        else
          echo "üî• Using existing firewall: ${FIREWALL_NAME} (${FIREWALL_ID})"
        fi
        
        echo "firewall-id=${FIREWALL_ID}" >> $GITHUB_OUTPUT

    - name: Create or update load balancer
      id: load-balancer
      run: |
        LB_NAME="${{ env.DEPLOYMENT_NAME }}-lb-${{ needs.validate-deployment.outputs.deployment-environment }}"
        
        # Check if load balancer exists
        LB_ID=$(doctl compute load-balancer list --format ID,Name --no-header | grep "${LB_NAME}" | cut -d' ' -f1)
        
        if [[ -z "$LB_ID" ]]; then
          echo "‚öñÔ∏è Creating new load balancer: ${LB_NAME}"
          LB_ID=$(doctl compute load-balancer create \
            --name "${LB_NAME}" \
            --region "${{ env.DO_REGION }}" \
            --size lb-small \
            --algorithm round_robin \
            --forwarding-rules "entry_protocol:http,entry_port:80,target_protocol:http,target_port:8080,health_check_protocol:http,health_check_port:8080,health_check_path:/health" \
            --health-check "protocol:http,port:8080,path:/health,check_interval_seconds:10,response_timeout_seconds:5,unhealthy_threshold:3,healthy_threshold:2" \
            --format ID --no-header)
        else
          echo "‚öñÔ∏è Using existing load balancer: ${LB_NAME} (${LB_ID})"
        fi
        
        echo "load-balancer-id=${LB_ID}" >> $GITHUB_OUTPUT

    - name: Provision standard droplets
      id: droplets
      run: |
        DROPLET_COUNT="${{ needs.validate-deployment.outputs.droplet-count }}"
        DROPLET_NAME_PREFIX="${{ env.DEPLOYMENT_NAME }}-${{ needs.validate-deployment.outputs.deployment-environment }}"
        
        echo "üñ•Ô∏è Provisioning ${DROPLET_COUNT} standard droplets..."
        
        # Create user data script
        cat > droplet-init.sh << 'EOF'
        #!/bin/bash
        set -e
        
        # Update system
        apt-get update && apt-get upgrade -y
        
        # Install Docker
        curl -fsSL https://get.docker.com -o get-docker.sh
        sh get-docker.sh
        usermod -aG docker root
        
        # Install monitoring agent
        curl -sSL https://repos.insights.digitalocean.com/install.sh | sudo bash
        
        # Configure firewall
        ufw --force enable
        ufw allow ssh
        ufw allow 8080/tcp
        ufw allow 50051/tcp
        ufw allow 9090/tcp
        
        # Create orbit user
        useradd -m -s /bin/bash orbit
        usermod -aG docker orbit
        
        # Create directories
        mkdir -p /opt/orbit-rs/{config,data,logs}
        chown -R orbit:orbit /opt/orbit-rs
        
        echo "Standard droplet initialization complete"
        EOF
        
        # Create droplets
        DROPLET_IDS=""
        for i in $(seq 1 ${DROPLET_COUNT}); do
          DROPLET_NAME="${DROPLET_NAME_PREFIX}-${i}"
          
          # Check if droplet exists
          EXISTING_ID=$(doctl compute droplet list --format ID,Name --no-header | grep "${DROPLET_NAME}" | cut -d' ' -f1)
          
          if [[ -z "$EXISTING_ID" ]]; then
            echo "Creating droplet: ${DROPLET_NAME}"
            DROPLET_ID=$(doctl compute droplet create "${DROPLET_NAME}" \
              --image ubuntu-22-04-x64 \
              --size s-2vcpu-4gb \
              --region "${{ env.DO_REGION }}" \
              --vpc-uuid "${{ steps.vpc.outputs.vpc-id }}" \
              --user-data-file droplet-init.sh \
              --tag-names "${{ env.DEPLOYMENT_NAME }},standard-compute,${{ needs.validate-deployment.outputs.deployment-environment }}" \
              --ssh-keys "${{ secrets.DO_SSH_KEY_ID }}" \
              --wait \
              --format ID --no-header)
            
            # Add to firewall
            doctl compute firewall add-droplets "${{ steps.firewall.outputs.firewall-id }}" --droplet-ids "${DROPLET_ID}"
          else
            echo "Using existing droplet: ${DROPLET_NAME} (${EXISTING_ID})"
            DROPLET_ID="${EXISTING_ID}"
          fi
          
          if [[ -z "$DROPLET_IDS" ]]; then
            DROPLET_IDS="${DROPLET_ID}"
          else
            DROPLET_IDS="${DROPLET_IDS},${DROPLET_ID}"
          fi
        done
        
        echo "droplet-ids=${DROPLET_IDS}" >> $GITHUB_OUTPUT
        echo "‚úÖ Standard droplets provisioned: ${DROPLET_IDS}"

    - name: Provision GPU droplets
      id: gpu-droplets
      if: needs.validate-deployment.outputs.enable-gpu == 'true'
      run: |
        GPU_DROPLET_COUNT="${{ needs.validate-deployment.outputs.gpu-droplet-count }}"
        DROPLET_NAME_PREFIX="${{ env.DEPLOYMENT_NAME }}-gpu-${{ needs.validate-deployment.outputs.deployment-environment }}"
        
        echo "üöÄ Provisioning ${GPU_DROPLET_COUNT} GPU droplets..."
        
        # Create GPU-specific user data script
        cat > gpu-droplet-init.sh << 'EOF'
        #!/bin/bash
        set -e
        
        # Update system
        apt-get update && apt-get upgrade -y
        
        # Install Docker
        curl -fsSL https://get.docker.com -o get-docker.sh
        sh get-docker.sh
        usermod -aG docker root
        
        # Install NVIDIA drivers and CUDA
        wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
        mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
        wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda-repo-ubuntu2204-12-2-local_12.2.0-535.54.03-1_amd64.deb
        dpkg -i cuda-repo-ubuntu2204-12-2-local_12.2.0-535.54.03-1_amd64.deb
        cp /var/cuda-repo-ubuntu2204-12-2-local/cuda-*-keyring.gpg /usr/share/keyrings/
        apt-get update
        apt-get -y install cuda
        
        # Install NVIDIA Container Toolkit
        distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
        curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
        curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
          sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
          sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
        apt-get update
        apt-get install -y nvidia-container-toolkit
        nvidia-ctk runtime configure --runtime=docker
        systemctl restart docker
        
        # Enable persistence mode
        nvidia-smi -pm 1
        
        # Install monitoring
        curl -sSL https://repos.insights.digitalocean.com/install.sh | sudo bash
        
        # Configure firewall
        ufw --force enable
        ufw allow ssh
        ufw allow 8080/tcp
        ufw allow 50051/tcp
        ufw allow 9090/tcp
        
        # Create orbit user
        useradd -m -s /bin/bash orbit
        usermod -aG docker orbit
        
        # Create directories
        mkdir -p /opt/orbit-rs/{config,data,logs}
        chown -R orbit:orbit /opt/orbit-rs
        
        echo "GPU droplet initialization complete"
        nvidia-smi  # Display GPU info
        EOF
        
        # Create GPU droplets
        GPU_DROPLET_IDS=""
        for i in $(seq 1 ${GPU_DROPLET_COUNT}); do
          DROPLET_NAME="${DROPLET_NAME_PREFIX}-${i}"
          
          # Check if droplet exists
          EXISTING_ID=$(doctl compute droplet list --format ID,Name --no-header | grep "${DROPLET_NAME}" | cut -d' ' -f1)
          
          if [[ -z "$EXISTING_ID" ]]; then
            echo "Creating GPU droplet: ${DROPLET_NAME}"
            # Note: GPU droplet sizes may vary by region and availability
            DROPLET_ID=$(doctl compute droplet create "${DROPLET_NAME}" \
              --image gpu-h100x1-base \
              --size gd-8vcpu-32gb-nvidia-h100x1 \
              --region "${{ env.DO_REGION }}" \
              --vpc-uuid "${{ steps.vpc.outputs.vpc-id }}" \
              --user-data-file gpu-droplet-init.sh \
              --tag-names "${{ env.DEPLOYMENT_NAME }},gpu-compute,ml-workload,${{ needs.validate-deployment.outputs.deployment-environment }}" \
              --ssh-keys "${{ secrets.DO_SSH_KEY_ID }}" \
              --wait \
              --format ID --no-header) || {
              echo "‚ö†Ô∏è GPU droplet creation failed, trying alternative size..."
              DROPLET_ID=$(doctl compute droplet create "${DROPLET_NAME}" \
                --image ubuntu-22-04-x64 \
                --size g-4vcpu-16gb \
                --region "${{ env.DO_REGION }}" \
                --vpc-uuid "${{ steps.vpc.outputs.vpc-id }}" \
                --user-data-file gpu-droplet-init.sh \
                --tag-names "${{ env.DEPLOYMENT_NAME }},gpu-compute,fallback,${{ needs.validate-deployment.outputs.deployment-environment }}" \
                --ssh-keys "${{ secrets.DO_SSH_KEY_ID }}" \
                --wait \
                --format ID --no-header)
            }
            
            # Add to firewall
            doctl compute firewall add-droplets "${{ steps.firewall.outputs.firewall-id }}" --droplet-ids "${DROPLET_ID}"
          else
            echo "Using existing GPU droplet: ${DROPLET_NAME} (${EXISTING_ID})"
            DROPLET_ID="${EXISTING_ID}"
          fi
          
          if [[ -z "$GPU_DROPLET_IDS" ]]; then
            GPU_DROPLET_IDS="${DROPLET_ID}"
          else
            GPU_DROPLET_IDS="${GPU_DROPLET_IDS},${DROPLET_ID}"
          fi
        done
        
        echo "gpu-droplet-ids=${GPU_DROPLET_IDS}" >> $GITHUB_OUTPUT
        echo "‚úÖ GPU droplets provisioned: ${GPU_DROPLET_IDS}"

    - name: Configure Spaces object storage
      run: |
        SPACES_NAME="${{ env.DEPLOYMENT_NAME }}-${{ needs.validate-deployment.outputs.deployment-environment }}-storage"
        
        # Create Spaces bucket if it doesn't exist
        doctl spaces bucket create "${SPACES_NAME}" \
          --region "${{ env.DO_REGION }}" || echo "Spaces bucket may already exist"
        
        # Configure CORS for web access
        cat > cors-config.json << EOF
        {
          "CORSRules": [
            {
              "AllowedHeaders": ["*"],
              "AllowedMethods": ["GET", "POST", "PUT", "DELETE", "HEAD"],
              "AllowedOrigins": ["*"],
              "MaxAgeSeconds": 3000
            }
          ]
        }
        EOF
        
        doctl spaces bucket put-cors "${SPACES_NAME}" --config cors-config.json || echo "CORS configuration may not be supported"
        
        echo "‚úÖ Digital Ocean Spaces configured: ${SPACES_NAME}"

  # ============================================================================
  # APPLICATION DEPLOYMENT
  # ============================================================================

  deploy-application:
    name: Deploy Orbit-RS Application
    runs-on: ubuntu-latest
    needs: [validate-deployment, provision-infrastructure]
    if: needs.validate-deployment.outputs.deploy-to-do == 'true'
    environment: ${{ needs.validate-deployment.outputs.deployment-environment }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install doctl
      uses: digitalocean/action-doctl@v2
      with:
        token: ${{ secrets.DO_API_TOKEN }}

    - name: Log in to Container Registry
      run: |
        echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin

    - name: Deploy to standard droplets
      run: |
        IFS=',' read -ra DROPLET_IDS <<< "${{ needs.provision-infrastructure.outputs.droplet-ids }}"
        
        for DROPLET_ID in "${DROPLET_IDS[@]}"; do
          echo "üöÄ Deploying to droplet: ${DROPLET_ID}"
          
          # Get droplet IP
          DROPLET_IP=$(doctl compute droplet get "${DROPLET_ID}" --format PublicIPv4 --no-header)
          
          # Create deployment script
          cat > deploy-script.sh << EOF
        #!/bin/bash
        set -e
        
        # Pull latest images
        docker pull ${{ env.CONTAINER_REGISTRY }}/orbit-server:latest
        docker pull ${{ env.CONTAINER_REGISTRY }}/orbit-client:latest
        docker pull ${{ env.CONTAINER_REGISTRY }}/orbit-operator:latest
        
        # Stop existing containers
        docker stop orbit-server orbit-client orbit-operator 2>/dev/null || true
        docker rm orbit-server orbit-client orbit-operator 2>/dev/null || true
        
        # Start orbit-server
        docker run -d \
          --name orbit-server \
          --restart unless-stopped \
          -p 50051:50051 \
          -p 8080:8080 \
          -p 9090:9090 \
          -v /opt/orbit-rs/config:/app/config \
          -v /opt/orbit-rs/data:/app/data \
          -v /opt/orbit-rs/logs:/app/logs \
          -e DEPLOYMENT_MODE=digital_ocean \
          -e DO_REGION=${{ env.DO_REGION }} \
          -e DO_SPACES_NAME=${{ env.DEPLOYMENT_NAME }}-${{ needs.validate-deployment.outputs.deployment-environment }}-storage \
          -e DO_SPACES_REGION=${{ env.DO_REGION }} \
          -e DO_SPACES_ACCESS_KEY=${{ secrets.DO_SPACES_ACCESS_KEY }} \
          -e DO_SPACES_SECRET_KEY=${{ secrets.DO_SPACES_SECRET_KEY }} \
          -e RUST_LOG=info \
          ${{ env.CONTAINER_REGISTRY }}/orbit-server:latest
        
        # Start orbit-client
        docker run -d \
          --name orbit-client \
          --restart unless-stopped \
          --network container:orbit-server \
          -v /opt/orbit-rs/config:/app/config \
          -e ORBIT_SERVER_URL=http://localhost:50051 \
          ${{ env.CONTAINER_REGISTRY }}/orbit-client:latest
        
        # Start orbit-operator
        docker run -d \
          --name orbit-operator \
          --restart unless-stopped \
          --network container:orbit-server \
          -v /opt/orbit-rs/config:/app/config \
          -e ORBIT_SERVER_URL=http://localhost:50051 \
          ${{ env.CONTAINER_REGISTRY }}/orbit-operator:latest
        
        echo "Deployment completed on \$(hostname)"
        docker ps
        EOF
          
          # Copy and execute deployment script
          doctl compute ssh "${DROPLET_ID}" --ssh-command "sudo bash -s" < deploy-script.sh
          
          # Add to load balancer
          doctl compute load-balancer add-droplets "${{ needs.provision-infrastructure.outputs.load-balancer-id }}" --droplet-ids "${DROPLET_ID}"
          
          echo "‚úÖ Deployed to droplet ${DROPLET_ID} (${DROPLET_IP})"
        done

    - name: Deploy to GPU droplets
      if: needs.validate-deployment.outputs.enable-gpu == 'true'
      run: |
        IFS=',' read -ra GPU_DROPLET_IDS <<< "${{ needs.provision-infrastructure.outputs.gpu-droplet-ids }}"
        
        for DROPLET_ID in "${GPU_DROPLET_IDS[@]}"; do
          echo "üöÄ Deploying to GPU droplet: ${DROPLET_ID}"
          
          # Get droplet IP
          DROPLET_IP=$(doctl compute droplet get "${DROPLET_ID}" --format PublicIPv4 --no-header)
          
          # Create GPU deployment script
          cat > gpu-deploy-script.sh << EOF
        #!/bin/bash
        set -e
        
        # Pull latest GPU-optimized images
        docker pull ${{ env.CONTAINER_REGISTRY }}/orbit-server:latest-gpu
        docker pull ${{ env.CONTAINER_REGISTRY }}/orbit-compute:latest-gpu
        
        # Stop existing containers
        docker stop orbit-server-gpu orbit-compute-gpu 2>/dev/null || true
        docker rm orbit-server-gpu orbit-compute-gpu 2>/dev/null || true
        
        # Start GPU-enabled orbit-server
        docker run -d \
          --name orbit-server-gpu \
          --restart unless-stopped \
          --gpus all \
          -p 50051:50051 \
          -p 8080:8080 \
          -p 9090:9090 \
          -v /opt/orbit-rs/config:/app/config \
          -v /opt/orbit-rs/data:/app/data \
          -v /opt/orbit-rs/logs:/app/logs \
          -e DEPLOYMENT_MODE=digital_ocean \
          -e DO_REGION=${{ env.DO_REGION }} \
          -e DO_SPACES_NAME=${{ env.DEPLOYMENT_NAME }}-${{ needs.validate-deployment.outputs.deployment-environment }}-storage \
          -e DO_SPACES_REGION=${{ env.DO_REGION }} \
          -e DO_SPACES_ACCESS_KEY=${{ secrets.DO_SPACES_ACCESS_KEY }} \
          -e DO_SPACES_SECRET_KEY=${{ secrets.DO_SPACES_SECRET_KEY }} \
          -e NVIDIA_VISIBLE_DEVICES=all \
          -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \
          -e RUST_LOG=info \
          -e GPU_ENABLED=true \
          ${{ env.CONTAINER_REGISTRY }}/orbit-server:latest-gpu
        
        # Start GPU-optimized compute engine
        docker run -d \
          --name orbit-compute-gpu \
          --restart unless-stopped \
          --gpus all \
          --network container:orbit-server-gpu \
          -v /opt/orbit-rs/config:/app/config \
          -v /opt/orbit-rs/data:/app/data \
          -e ORBIT_SERVER_URL=http://localhost:50051 \
          -e NVIDIA_VISIBLE_DEVICES=all \
          -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \
          -e GPU_ENABLED=true \
          -e GPU_MEMORY_FRACTION=0.8 \
          ${{ env.CONTAINER_REGISTRY }}/orbit-compute:latest-gpu
        
        echo "GPU deployment completed on \$(hostname)"
        nvidia-smi
        docker ps
        EOF
          
          # Copy and execute GPU deployment script
          doctl compute ssh "${DROPLET_ID}" --ssh-command "sudo bash -s" < gpu-deploy-script.sh
          
          echo "‚úÖ Deployed to GPU droplet ${DROPLET_ID} (${DROPLET_IP})"
        done

    - name: Configure monitoring
      run: |
        echo "üìä Configuring monitoring and alerting..."
        
        # Create monitoring configuration
        cat > monitoring-config.yml << EOF
        global:
          scrape_interval: 15s
        scrape_configs:
          - job_name: 'orbit-rs'
            static_configs:
        EOF
        
        # Add standard droplets to monitoring
        IFS=',' read -ra DROPLET_IDS <<< "${{ needs.provision-infrastructure.outputs.droplet-ids }}"
        for DROPLET_ID in "${DROPLET_IDS[@]}"; do
          DROPLET_IP=$(doctl compute droplet get "${DROPLET_ID}" --format PrivateIPv4 --no-header)
          echo "              - targets: ['${DROPLET_IP}:9090']" >> monitoring-config.yml
        done
        
        # Add GPU droplets to monitoring if enabled
        if [[ "${{ needs.validate-deployment.outputs.enable-gpu }}" == "true" ]]; then
          IFS=',' read -ra GPU_DROPLET_IDS <<< "${{ needs.provision-infrastructure.outputs.gpu-droplet-ids }}"
          for DROPLET_ID in "${GPU_DROPLET_IDS[@]}"; do
            DROPLET_IP=$(doctl compute droplet get "${DROPLET_ID}" --format PrivateIPv4 --no-header)
            echo "              - targets: ['${DROPLET_IP}:9090']" >> monitoring-config.yml
          done
        fi
        
        echo "‚úÖ Monitoring configuration created"

  # ============================================================================
  # HEALTH CHECKS AND VALIDATION
  # ============================================================================

  validate-deployment:
    name: Validate Deployment Health
    runs-on: ubuntu-latest
    needs: [validate-deployment, provision-infrastructure, deploy-application]
    if: needs.validate-deployment.outputs.deploy-to-do == 'true'
    steps:
    - name: Install doctl
      uses: digitalocean/action-doctl@v2
      with:
        token: ${{ secrets.DO_API_TOKEN }}

    - name: Check load balancer health
      run: |
        LB_ID="${{ needs.provision-infrastructure.outputs.load-balancer-id }}"
        echo "üîç Checking load balancer health..."
        
        # Wait for load balancer to become active
        for i in {1..30}; do
          LB_STATUS=$(doctl compute load-balancer get "${LB_ID}" --format Status --no-header)
          if [[ "$LB_STATUS" == "active" ]]; then
            echo "‚úÖ Load balancer is active"
            break
          fi
          echo "‚è≥ Load balancer status: ${LB_STATUS}. Waiting..."
          sleep 10
        done
        
        # Get load balancer IP
        LB_IP=$(doctl compute load-balancer get "${LB_ID}" --format IP --no-header)
        echo "üìç Load balancer IP: ${LB_IP}"
        
        # Test health endpoint
        for i in {1..10}; do
          if curl -f "http://${LB_IP}/health"; then
            echo "‚úÖ Health check passed"
            break
          else
            echo "‚è≥ Health check failed, retrying in 30s..."
            sleep 30
          fi
        done

    - name: Check droplet health
      run: |
        echo "üîç Checking individual droplet health..."
        
        # Check standard droplets
        IFS=',' read -ra DROPLET_IDS <<< "${{ needs.provision-infrastructure.outputs.droplet-ids }}"
        for DROPLET_ID in "${DROPLET_IDS[@]}"; do
          DROPLET_IP=$(doctl compute droplet get "${DROPLET_ID}" --format PublicIPv4 --no-header)
          DROPLET_NAME=$(doctl compute droplet get "${DROPLET_ID}" --format Name --no-header)
          
          echo "Checking droplet: ${DROPLET_NAME} (${DROPLET_IP})"
          
          # Test health endpoint directly
          if curl -f "http://${DROPLET_IP}:8080/health"; then
            echo "‚úÖ Droplet ${DROPLET_NAME} is healthy"
          else
            echo "‚ùå Droplet ${DROPLET_NAME} health check failed"
          fi
        done
        
        # Check GPU droplets if enabled
        if [[ "${{ needs.validate-deployment.outputs.enable-gpu }}" == "true" ]]; then
          IFS=',' read -ra GPU_DROPLET_IDS <<< "${{ needs.provision-infrastructure.outputs.gpu-droplet-ids }}"
          for DROPLET_ID in "${GPU_DROPLET_IDS[@]}"; do
            DROPLET_IP=$(doctl compute droplet get "${DROPLET_ID}" --format PublicIPv4 --no-header)
            DROPLET_NAME=$(doctl compute droplet get "${DROPLET_ID}" --format Name --no-header)
            
            echo "Checking GPU droplet: ${DROPLET_NAME} (${DROPLET_IP})"
            
            # Test health endpoint and GPU status
            if curl -f "http://${DROPLET_IP}:8080/health"; then
              echo "‚úÖ GPU droplet ${DROPLET_NAME} is healthy"
              
              # Check GPU status
              doctl compute ssh "${DROPLET_ID}" --ssh-command "nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv"
            else
              echo "‚ùå GPU droplet ${DROPLET_NAME} health check failed"
            fi
          done
        fi

  # ============================================================================
  # NOTIFICATION AND REPORTING
  # ============================================================================

  notify-deployment:
    name: Send Deployment Notification
    runs-on: ubuntu-latest
    needs: [validate-deployment, provision-infrastructure, deploy-application, validate-deployment]
    if: always() && needs.validate-deployment.outputs.deploy-to-do == 'true'
    steps:
    - name: Report deployment status
      run: |
        if [[ "${{ job.status }}" == "success" ]]; then
          echo "üéâ Digital Ocean deployment completed successfully!"
          echo "üåü Environment: ${{ needs.validate-deployment.outputs.deployment-environment }}"
          echo "üñ•Ô∏è Standard droplets: ${{ needs.validate-deployment.outputs.droplet-count }}"
          if [[ "${{ needs.validate-deployment.outputs.enable-gpu }}" == "true" ]]; then
            echo "üöÄ GPU droplets: ${{ needs.validate-deployment.outputs.gpu-droplet-count }}"
          fi
          echo "‚öñÔ∏è Load balancer: ${{ needs.provision-infrastructure.outputs.load-balancer-id }}"
        else
          echo "‚ùå Digital Ocean deployment failed!"
          echo "Please check the workflow logs for details."
        fi