---
# DaemonSet to prepare nodes for memory-mapped file optimization
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: orbit-mmap-node-prep
  namespace: orbit-rs
  labels:
    app.kubernetes.io/name: orbit-rs
    app.kubernetes.io/component: node-preparation
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: orbit-rs
      app.kubernetes.io/component: node-preparation
  template:
    metadata:
      labels:
        app.kubernetes.io/name: orbit-rs
        app.kubernetes.io/component: node-preparation
    spec:
      hostNetwork: true
      hostPID: true
      tolerations:
      - operator: Exists  # Run on all nodes
      nodeSelector:
        orbit-rs/mmap-optimized: "true"  # Only on labeled nodes
      containers:
      - name: node-prep
        image: alpine:3.18
        command: ["/bin/sh"]
        args: ["-c", "while true; do /app/scripts/monitor-node.sh; sleep 60; done"]
        securityContext:
          privileged: true
        volumeMounts:
        - name: host-sys
          mountPath: /host/sys
        - name: host-proc
          mountPath: /host/proc
        - name: scripts
          mountPath: /app/scripts
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
      initContainers:
      - name: node-init
        image: alpine:3.18
        command: ["/bin/sh"]
        args: ["/app/scripts/init-node.sh"]
        securityContext:
          privileged: true
        volumeMounts:
        - name: host-sys
          mountPath: /host/sys
        - name: host-proc
          mountPath: /host/proc
        - name: scripts
          mountPath: /app/scripts
      volumes:
      - name: host-sys
        hostPath:
          path: /sys
      - name: host-proc
        hostPath:
          path: /proc
      - name: scripts
        configMap:
          name: orbit-node-scripts
          defaultMode: 0755

---
# ConfigMap with node preparation scripts
apiVersion: v1
kind: ConfigMap
metadata:
  name: orbit-node-scripts
  namespace: orbit-rs
  labels:
    app.kubernetes.io/name: orbit-rs
    app.kubernetes.io/component: node-scripts
data:
  init-node.sh: |
    #!/bin/sh
    echo "Initializing node ${NODE_NAME} for memory-mapped file optimization"
    
    # Configure transparent huge pages
    echo "Configuring transparent huge pages..."
    if [ -d /host/sys/kernel/mm/transparent_hugepage ]; then
        echo madvise > /host/sys/kernel/mm/transparent_hugepage/enabled
        echo defer > /host/sys/kernel/mm/transparent_hugepage/defrag
        echo 1 > /host/sys/kernel/mm/transparent_hugepage/khugepaged/defrag
        echo 32 > /host/sys/kernel/mm/transparent_hugepage/khugepaged/pages_to_scan
    fi
    
    # Configure kernel parameters for mmap
    echo "Setting kernel parameters..."
    echo 2097152 > /host/proc/sys/vm/max_map_count
    echo 4096 > /host/proc/sys/vm/mmap_min_addr
    echo 68719476736 > /host/proc/sys/kernel/shmmax
    echo 4294967296 > /host/proc/sys/kernel/shmall
    echo 6815744 > /host/proc/sys/fs/file-max
    echo 1048576 > /host/proc/sys/fs/nr_open
    
    # Memory management settings
    echo 5 > /host/proc/sys/vm/dirty_background_ratio
    echo 10 > /host/proc/sys/vm/dirty_ratio
    echo 3000 > /host/proc/sys/vm/dirty_expire_centisecs
    echo 500 > /host/proc/sys/vm/dirty_writeback_centisecs
    echo 1 > /host/proc/sys/vm/drop_caches
    
    # Network optimizations for cluster communication
    echo 134217728 > /host/proc/sys/net/core/rmem_max
    echo 134217728 > /host/proc/sys/net/core/wmem_max
    echo 32768 > /host/proc/sys/net/core/somaxconn
    
    # I/O scheduler optimization for NVMe
    for disk in /host/sys/block/nvme*; do
        if [ -d "$disk" ]; then
            echo "Optimizing $(basename $disk)..."
            echo none > $disk/queue/scheduler 2>/dev/null || true
            echo 1 > $disk/queue/nomerges 2>/dev/null || true
            echo 32 > $disk/queue/nr_requests 2>/dev/null || true
        fi
    done
    
    echo "Node initialization complete"

  monitor-node.sh: |
    #!/bin/sh
    # Continuous monitoring and optimization
    
    # Check and maintain THP settings
    if [ -f /host/sys/kernel/mm/transparent_hugepage/enabled ]; then
        current=$(cat /host/sys/kernel/mm/transparent_hugepage/enabled)
        if ! echo "$current" | grep -q "\[madvise\]"; then
            echo madvise > /host/sys/kernel/mm/transparent_hugepage/enabled
        fi
    fi
    
    # Monitor memory pressure and adjust
    if [ -f /host/proc/meminfo ]; then
        available=$(grep MemAvailable /host/proc/meminfo | awk '{print $2}')
        total=$(grep MemTotal /host/proc/meminfo | awk '{print $2}')
        percent=$((available * 100 / total))
        
        if [ $percent -lt 10 ]; then
            echo "Memory pressure detected, dropping caches"
            echo 1 > /host/proc/sys/vm/drop_caches
        fi
    fi
    
    # Check mmap count limits
    current_max=$(cat /host/proc/sys/vm/max_map_count)
    if [ "$current_max" -lt 2097152 ]; then
        echo 2097152 > /host/proc/sys/vm/max_map_count
    fi

---
# ServiceMonitor for Prometheus to monitor mmap-specific metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: orbit-mmap-metrics
  namespace: orbit-rs
  labels:
    app.kubernetes.io/name: orbit-rs
    app.kubernetes.io/component: mmap-monitoring
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: orbit-rs
      app.kubernetes.io/component: mmap-server
  endpoints:
  - port: metrics
    interval: 15s
    path: /metrics
    honorLabels: true
    relabelings:
    - sourceLabels: [__meta_kubernetes_pod_name]
      targetLabel: pod
    - sourceLabels: [__meta_kubernetes_namespace]
      targetLabel: namespace
    - sourceLabels: [__meta_kubernetes_pod_node_name]
      targetLabel: node

---
# PrometheusRule for mmap-specific alerts
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: orbit-mmap-alerts
  namespace: orbit-rs
  labels:
    app.kubernetes.io/name: orbit-rs
    app.kubernetes.io/component: mmap-alerts
spec:
  groups:
  - name: orbit-mmap.rules
    rules:
    
    # Memory pressure alerts
    - alert: OrbitMMapMemoryPressureHigh
      expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) < 0.1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High memory pressure on {{ $labels.node }}"
        description: "Node {{ $labels.node }} has less than 10% memory available"
    
    # Page fault rate alerts
    - alert: OrbitMMapPageFaultRateHigh
      expr: rate(orbit_mmap_page_faults_total[5m]) > 10000
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High page fault rate on {{ $labels.pod }}"
        description: "Pod {{ $labels.pod }} has high page fault rate: {{ $value }} faults/sec"
    
    # Storage space alerts
    - alert: OrbitMMapStorageSpaceLow
      expr: (node_filesystem_avail_bytes{mountpoint="/mnt/mmap-data"} / node_filesystem_size_bytes{mountpoint="/mnt/mmap-data"}) < 0.2
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Low storage space on {{ $labels.node }}"
        description: "mmap storage on {{ $labels.node }} has less than 20% space available"
    
    # Actor activation performance
    - alert: OrbitMMapActorActivationSlow
      expr: histogram_quantile(0.95, rate(orbit_actor_activation_duration_seconds_bucket[5m])) > 1
      for: 3m
      labels:
        severity: warning
      annotations:
        summary: "Slow actor activation on {{ $labels.pod }}"
        description: "95th percentile actor activation time is {{ $value }}s"
    
    # mmap region health
    - alert: OrbitMMapRegionUnhealthy
      expr: up{job="orbit-mmap-metrics"} == 0
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "Orbit mmap instance down"
        description: "Orbit mmap instance {{ $labels.pod }} is down"

---
# Grafana Dashboard ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: orbit-mmap-dashboard
  namespace: orbit-rs
  labels:
    app.kubernetes.io/name: orbit-rs
    app.kubernetes.io/component: mmap-dashboard
    grafana_dashboard: "true"
data:
  dashboard.json: |
    {
      "dashboard": {
        "id": null,
        "title": "Orbit-RS Memory-Mapped File Performance",
        "tags": ["orbit-rs", "mmap", "performance"],
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "Memory Usage",
            "type": "graph",
            "targets": [
              {
                "expr": "node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes",
                "legendFormat": "Used Memory"
              },
              {
                "expr": "node_memory_Cached_bytes",
                "legendFormat": "Page Cache"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Page Fault Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(orbit_mmap_page_faults_total[1m])",
                "legendFormat": "Page Faults/sec - {{ pod }}"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
          },
          {
            "id": 3,
            "title": "Actor Performance",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(orbit_actor_activations_total[1m])",
                "legendFormat": "Activations/sec - {{ pod }}"
              },
              {
                "expr": "histogram_quantile(0.95, rate(orbit_actor_activation_duration_seconds_bucket[5m]))",
                "legendFormat": "P95 Activation Time - {{ pod }}"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
          },
          {
            "id": 4,
            "title": "Storage I/O",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(node_disk_reads_completed_total[1m])",
                "legendFormat": "Reads/sec - {{ device }}"
              },
              {
                "expr": "rate(node_disk_writes_completed_total[1m])",
                "legendFormat": "Writes/sec - {{ device }}"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "refresh": "10s"
      }
    }